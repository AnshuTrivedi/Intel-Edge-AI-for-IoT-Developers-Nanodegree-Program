{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantizing a Model using DL Workbench\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section, we will see how we can use the DL Workbench to quantize a model.\n",
    "* To quantize a model to use INT8 weights and activations during inference, DL workbench needs a small subset of the actual data that was used to train the model (which in this case is ImageNet). This means that we cannot use the autogenerated data anymore.\n",
    "\n",
    "To be able to follow along with this video you will need to first download a small set of ImageNet data (100 should be enough) and then create a dataset in the ImageNet format. Instructions on how to create a dataset can be found [here.](https://docs.openvinotoolkit.org/latest/_docs_Workbench_DG_Dataset_Types.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Depending on your hardware and the model you use, you may find that the quantized model has a worse performance than the original model` (you can see that this is the result I got in the video). DL Workbench `only quantizes some layers to use INT8 weights instead of Float weights` (depending on the accuracy drop value you selected).\n",
    "* This is what makes performing INT8 inference is faster. However, some hardware (and software) configurations cannot perform INT8 operations as optimally as FLOAT operations. You can find more details about those prerequisites and configurations [here.](https://docs.openvinotoolkit.org/2020.1/_docs_IE_DG_Int8Inference.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Quantizing a Model using DL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`In this exercise, you'll quantize a model using the DL Workbench to INT8 and then compare the performance of models quantized using different Max Accuracy Drop values.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are your tasks for this exercise:\n",
    "\n",
    "Task List\n",
    "* Load model on to DL Workbench. Note: This model should not be already converted into IR format.\n",
    "* Import load dataset in either the VOC or Imagenet format.\n",
    "* convert the model to INT8\n",
    "* Compare the performance of Quantized model and high precision model\n",
    "* Quantize the same model again with different `Max Accuracy Drop` and compare the performance of two quantize model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
